****
# День 1. Управление виртуальным ЦОД <a name="2"></a>

Понятие виртуализации в широком смысле представляет собой сокрытие настоящей реализации какого-либо объекта или процесса от истинного его представления для пользователя. Результатом виртуализации является нечто удобное для использования, на самом деле, имеющее более сложную или совсем иную структуру, отличную от той, которая воспринимается при работе с объектом. Происходит отделение представления от реализации. В компьютерных технологиях под термином «виртуализация» обычно понимается абстракция вычислительных ресурсов (чаще всего серверов) и предоставление пользователю системы, которая «инкапсулирует» (скрывает в себе) собственную реализацию. Проще говоря, пользователь работает с удобным для себя представлением объекта, и для него не имеет значения, как объект устроен в действительности.

![Виртуальные машины, работающие на физическом оборудовании](assets/virtualisation.png)
**Виртуальные машины, работающие на физическом оборудовании**

Долгое время в центрах обработки данных стремились к децентрализованной архитектуре, масштабированию приложений и системной инфраструктуры в горизонтальном направлении. Эта тенденция, как правило, приводила к росту числа серверов. Со временем инфраструктура ЦОД становилась все более сложной, что сказывалось на возможности его модернизации, обслуживании, стоимости и пр. Централизованная архитектура может уменьшить количество серверов и увеличить степень использования оборудования при сравнимой производительности, а так же уменьшить стоимость владения оборудованием. 

`Частичная виртуализация` (нативная виртуализация) базируется на принципе эмуляции только необходимого количества ресурсов, чтобы виртуальная машина могла быть запущена изолировано. Например, при полной эмуляции различных архитектур, гостевая система работает с определенной специфической системой команд процессора, отличной от системы команд процессора хостовой системы. Каждую команду процессору гостевой системы нужно транслировать в соответствующую команду хостовой системы, что невероятно уменьшает быстродействие. При использовании нативной виртуализации никакой трансляции команд не происходит, так как гостевая операционная система разработана под ту же архитектуру, на которой работает хостовая система. Это позволяет значительно повысить быстродействие гостевой системы и максимально приблизить его к быстродействию реальной системы.
Для повышения быстродействия нативной виртуализации применяется специализированная программная прослойка – `гипервизор`. Гипервизор является посредником между гостевой операционной системой и физическим аппаратным обеспечением. Он позволяет гостевой системе напрямую обращаться к аппаратным ресурсам, что и является секретом высокого быстродействия данного вида виртуализации. Гипервизор является одним из ключевых понятий в мире виртуализации.

Частичная эмуляция является самым распространенным видом виртуализации в наше время. Основным ее недостатком является зависимость виртуальных машин от конкретной аппаратной архитектуры [3].
Примеры продуктов для частичной эмуляции: `VMware Workstation, VMware Server, VMware ESXI Server, Virtual Iron, Microsoft Hyper-V Server, Microsoft Virtual PC, Sun VirtualBox, Parallels Desktop` и другие.

В хакатоне мы будем использовать ЦОД под управлением гипервизора `ESXi 6.5` и платформы централизованного управления `VMware vCenter`. Вы можете ознакомиться с документацией по `VMware vCenter` [[тут]](https://docs.vmware.com/en/VMware-vSphere/index.html). В комплекте с `vCenter` предоставляется веб-клиент `VMware vSphere Web Client`, с помощью которого можно управлять виртуальной инфраструктурой через один из распространенных браузеров c поддержкой `Flash Player`).

Для выполнения заданий хакатона для каждой команды выделен пул виртуальных ресурсов:

- Оперативная память:  8 ГБ.

- Эквивалентная микропроцессорная частота: 2400 МГц.

- Объем дискового пространства 50 ГБ.


****
## Доступ к виртальному ЦОД <a name="21"></a>

Для доступа к выделенному для команды пула ресурсов необходимо открыть страницу по адресу:

* [https://195.19.40.127/vsphere-client/?csp](https://195.19.40.127/vsphere-client/?csp)

Для доступа необходимо использовать логин и пароль, предоставленные организаторами хакатона.

![Доступ к VMware vCenter](assets/vmware.png)
**Доступ к VMware vCenter**

После ввода логина и пароля вы на главную административную панель `VMware vSphere Web Client` (т.н. Home).

![](assets/esx_1.png)
**Главную административную панель `VMware vSphere Web Client`**

При первом входе вам необходимо изменить пароль. 

Войдите в меню **Roles -> Users and Groups**. Выберите в списке вашу команду (team), введите текущий пароль и дважды новый пароль. Требования к сложности пароля: только цифры, не менее 6 цифр.

![](assets/esx_2.png)

****
## Создание виртуальной машины и установка ОС <a name="22"></a>

Перейдите из главной административной панели в раздел **Hosts and Clasters**.

Иерархия виртуального ЦОД сотсоит из следующих уровней:

1) Уровень Центра обработки данных: `195.19.40.127`

2) Уровен кластера: `IU6`

3) Уровень хоста: `195.19.40.124` или `195.19.40.125` или `195.19.40.126`. 

4) Уровень консолидированного вычислительного пула (так называемое виртуальное приложение `vAPP`): `team**`.

Дальнейшие действия необходимо производить только на уровне 4). Управление остальными уровнями иерархии выполняется только администратором ЦОД.

![](assets/esx_3.png)
**Иерархия виртуального ЦОД**

Вызовите контекстное меню для вычислительного пула. Выберите пункт **New Virtual Machine**.

![](assets/esx_4.png)
**Создание новой виртуальной машины**

Далее соледуйте указаниям диалога. 

В пункте **2a** выберите кластер для развертывания виртуальной машины: `IU6`. 

![](assets/esx_5_u.png)

В пункте **2b** выберите вычислительный пул: `team**`. 

![](assets/esx_6.png)

В диалоге выбора ресурсов виртуальной машины виберите следующие ресурсы:

- 2 CPU

- 8 GB RAM

- 20 GB HDD. 

![](assets/esx_8.png)

!!!По умолчанию выбирается так называемый Thick (толстый) тип диска. Все пространство такого диска выделяется в момент создания, при этом блоки не очищаются от данных, которые находились там ранее. Это может создавать потенциальные угрозы безопасности, поскольку виртуальная машина может получить доступ к данным на хранилище VMFS, которые ей не принадлежат. При обращении к блокам такого диска их содержимое предварительно не очищается со стороны ESX. Преимущество дисков типа thick - производительность и быстрота создания, недостаток - безопасность

Поэтому мы будем использовать диски типа Thin ("тонкие диски"), позволяющий автоматически расширять занимаемое дисковое пространство по мере заполнения диска. 
Эти диски создаются минимального размера и растут по мере их наполнения данными до выделенного объема. При выделении нового блока - он предварительно очищается. Эти диски наименее производительны (выделение нового блока и его очистка), однако наиболее оптимальны для экономии дискового пространства на системе хранения данных.

![](assets/esx_8_1.png)


Для установки операционной системы необходимо подключить виртуальный привод CD/DVD и смонтировать в него зустановочный образ системы. Выберите пункт **Datastore ISO file**. В открывшемся диалоге выберите идин из образов Ubuntu в папке **OS_images**. Включите пункт **Connect** для CD/DVD.

!!! Рекомендуется использовать версию ОС Linux без установленного рабочего стола. Например: `Ubuntu-18.04.3-live-server-amd64.iso`!!!


![](assets/esx_7_u.png)

Проверьте параметры ВМ. Создайте виртуальную машину.

![](assets/esx_9.png)

Теперь необходимо установить операционную систему. 

В контекстом меню ВМ выберите пункт **Power -> Power On**.

![](assets/esx_10.png)

Откройте консоль ВМ:

![](assets/esx_11.png)

Установите ОС со следующими сетевыминастройками:

Сетевые настройки: 

    IP адрес: выдается организаторами из диапазона 195.19.36.64/27

    Сетевая маска: /16 

    Шлюз: 195.19.36.65

    DNS: 195.19.32.2

![](assets/esx_12_u.png)

При установке серверной версии ОС Ubuntu обязательно разрешите использование LVM (Logical Volume Manager), что позволит расширять объем логических томов в процессе работы Linux.

![](assets/esx_13_u.png)

Разрешите установку и запуск OpenSSH сервера, что понадобится для соединения с Вашей виртуальной системой по протоколу SSH.

![](assets/esx_14_u.png)

После установки системы перегрузите виртуальную машину и выполните вход по введенным вами реквизитам пользователя.

![](assets/esx_15_u.png)

Проверьте, что сетевое соединение работает:

`ping www.ya.ru

Если соединение отсуствует, отредактируйте файл /etc/netplan/50-cloud-init.yaml. После этого актуализируйте конфигурацию сети по команде:

`sudo netplan apply

Используя терминал операционной системы можно выполнить пинг вашей системы:

`ping 195.19.36.66

`PING 195.19.36.66 (195.19.36.66) 56(84) bytes of data.

`64 bytes from 195.19.36.66: icmp_seq=1 ttl=58 time=5.94 ms

`64 bytes from 195.19.36.66: icmp_seq=2 ttl=58 time=5.79 ms


Если ваша система успешно пингуется, то можно подключиться к ней используя терминал с поддержкой протокола SSH (Tilix, Putty, term и пр.).
В ОС Linux это можно сделать по команде:

`ssh username@ip_address

где ip_address - ip адрес вашей виртуалки.


![](assets/esx_16.png)







