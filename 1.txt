****
# Введение <a name="1"></a>

Благодаря достижениям в области искусственного интеллекта в последние годы открываются новые области применения методов и алгоритмов машинного обучения. В то время как проекты машинного обучения различаются по размеру и сложности, требуя различных навыков работы с данными, их общая структура как правило одинакова. Можно констатировать, что для получения хороших результатов анализа, важно иметь хорошо подобранные данные и команду экспертов, обладающую необходимыми навыками для управления проектом машинного обучения. В этом исследовании мы будем следовать конвейеру машинного обучения, состоящему из шести ступеней.

![Последовательность этапов конвейера машинного обучения](assets/ml_pipeline.png)
**Последовательность этапов конвейера машинного обучения**

## Алгоритмы предварительной обработки данных <a name="1_1"></a>

Предварительная обработка данных - это метод анализа данных, который включает преобразование необработанных данных в понятный формат. Реальные данные часто являются неполными, непоследовательными и/или недостающими в определенных видах поведения или тенденциях и могут содержать много ошибок. Предварительная обработка данных является проверенным методом решения таких проблем. Поскольку это важно для успеха любого процесса машинного обучения, мы дадим краткое описание основных методов предварительной обработки данных, включая:

1) обработку пропущенных значений;

2) преобразование признаков, нормализацию и стандартизацию;

3) уменьшение размерности;

4) выбор признаков;

5) разделение данных.

Во-первых, сначала выполняется очистка данных, которая включает в себя вменения пропущенных значений и отбрасывание всех данных, которые имеют поврежденные значения или значения выбросов. Это требует высокого знания предметной области. Например, искаженные значения могут быть вызваны сбоем в работе механизма, который сгенерировал набор данных, или лицом, ответственным за запись данных. Только специалисты с высоким уровнем знаний в области могут определить, какие значения следует опускать, а какие показывают целесообразное измерение. Пропущенные значения обычно заменяются некоторыми правдоподобными значениями, такими как среднее или наиболее частое значение столбца.

Затем выполняется масштабирование объектов, чтобы поместить весь набор данных в один общий интервал. Очень важно, чтобы диапазон всех атрибутов был нормализован, чтобы каждый атрибут вносил одинаковый вклад в конечный результат [[1]](https://arxiv.org/abs/1811.03402). Это не должно влиять на тип категориальных атрибутов. Некоторыми популярными методами масштабирования функций являются нормализация мин-макс, нормализация среднего значения, логарифмическое преобразование и стандартизация атрибутов.

Затем выполняется разработка признаков. Разработка признаков в основном означает сохранение наиболее важных признаков для достижения желаемой цели. Это можно сделать, извлекая новые признаки из имеющихся в настоящее время признаки или удаляя признаки, которые не влияют на результат или добавляют шум, что приводит к снижению точности результатов.

Разделение данных - это разделение доступных данных на две или три части; обычно для перекрестных проверочных целей. Одна часть данных используется для разработки модели, а другая - для оценки производительности модели. Это сделано для предотвращения переобучения и улучшения способности модели работать с новыми данными.

## Алгоритмы машинного обучения <a name="1_2"></a>

Выбор правильного алгоритма является ключевой частью любого проекта по машинному обучению, и, поскольку есть десятки вариантов на выбор, важно понять их сильные и слабые стороны в различных бизнес-приложениях [[2]](https://www.researchgate.net/publication/316273553_A_Survey_on_Machine_Learning_Concept_Algorithms_and_Applications). В этом курсе мы поговорим об алгоритмах в двух видах обучения: 

- Обучение с учителем, 
   
- Обучение без учителя.


### Обучение с учителем <a name="1_2_1"></a>

Алгоритмы контролируемого обучения строят математическую модель набора данных, который содержит как входы, так и желаемые результаты. Данные известны как данные обучения и состоят из набора обучающих примеров. Каждый обучающий пример имеет один или несколько входов и желаемый выход, также известный как контрольный сигнал. В случае полуобучаемых алгоритмов, обучения в некоторых учебных примерах отсутствует желаемый результат. В математической модели каждый обучающий пример представлен массивом или вектором, а обучающие данные матрицей. Посредством итеративной оптимизации целевой функции, алгоритмы обучения с учителем изучают функцию, которая может использоваться для прогнозирования результатов, связанных с новыми входными данными. Оптимальная функция позволит алгоритму правильно определять выходные данные для входов, которые не были частью обучающих данных. 

Говорят, что алгоритм, улучшающий точность результатов или прогнозов с течением времени, научился выполнять эту задачу. Алгоритмы обучения с учителем включают классификацию и регрессию. Алгоритмы классификации используются, когда выходные данные ограничены ограниченным набором значений, а алгоритмы регрессии используются, когда выходные данные могут иметь любое числовое значение в пределах диапазона. Обучение сходству является областью контролируемого машинного обучения, тесно связанной с регрессией и классификацией, но цель состоит в том, чтобы учиться на примерах с использованием функции сходства, которая измеряет, насколько похожи или связаны два объекта. Оно имеет приложения для ранжирования, системы рекомендаций, визуального отслеживания личности, проверки лица и проверки докладчика.

### Обучение без учителя <a name="1_2_2"></a>

Алгоритмы обучения без учителя берут набор данных, который содержит только входные данные, и находят структуру данных, такую ​​как группировка или кластеризация точек данных. Алгоритмы поэтому учатся на тестовых данных, которые не были помечены, классифицированы или классифицированы. Вместо того, чтобы реагировать на обратную связь, неконтролируемые алгоритмы обучения выявляют общие черты в данных и реагируют на основании наличия или отсутствия таких общих черт в каждом новом фрагменте данных. 

*Кластерный анализ* - это распределение набора наблюдений в подмножества (называемые кластерами), чтобы наблюдения в пределах одного кластера были похожи в соответствии с одним или несколькими заранее определенными критериями, в то время как наблюдения, полученные из разных кластеров, отличаются. Различные методы кластеризации делают разные предположения о структуре данных, часто определяемые некоторой метрикой сходства и оцениваемые, например, по внутренней компактности или сходству между членами одного кластера и различию - разнице между кластерами. Другие методы основаны на оценке плотности и связности графа.



****
## Типовая вычислительная инфраструктура для машинного обучения  <a name="1_3"></a>

> 
>Под типовой системой машинного обучения в данном конкурсе понимается :
> 

-   ...
-   .

Примером подобной системы является структура, представленная на следующем рисунке.



****
## Проект хакатона <a name="1_4"></a>

Всем командам предлагается собрать template-проект, который может быть модифицирован командами для реализации собственных идей.
В проекте использовано следующее оборудование:

-   Облачная платформа `IBM Cloud Private` используется для реализации сервисов аналитической обработки и визуализации данных о пациентах в приватном медицинском учреждении (с возможностью полного доступа к персональной информации).

Система работает следующим образом. 


 

****
## Оборудование и настройка компьютера разработчика <a name="1_5"></a>

В ходе хакатона организаторы предоставят участникам следующее оборудование:

* ...

Требования к оборудованию разработкика:

* Учатник хакатона может выполнить все задания на компьютере в аудитории, однако рекомендуется использовать собственный ноутбук. Желательно использование операционной системы Linux (Ubuntu, Arch, CentOS, RHEL) или MacBook. В случае использования компьютера под управлением OC Windows рекомендуется воспользоваться готовым образом виртуальной машины, который можно найти на портале: [https://www.osboxes.org/ubuntu/](https://www.osboxes.org/ubuntu/).

****
# День 1. Управление виртуальным ЦОД <a name="2"></a>

Понятие виртуализации в широком смысле представляет собой сокрытие настоящей реализации какого-либо объекта или процесса от истинного его представления для пользователя. Результатом виртуализации является нечто удобное для использования, на самом деле, имеющее более сложную или совсем иную структуру, отличную от той, которая воспринимается при работе с объектом. Происходит отделение представления от реализации. В компьютерных технологиях под термином «виртуализация» обычно понимается абстракция вычислительных ресурсов (чаще всего серверов) и предоставление пользователю системы, которая «инкапсулирует» (скрывает в себе) собственную реализацию. Проще говоря, пользователь работает с удобным для себя представлением объекта, и для него не имеет значения, как объект устроен в действительности.

![Виртуальные машины, работающие на физическом оборудовании](assets/virtualisation.png)
**Виртуальные машины, работающие на физическом оборудовании**

Долгое время в центрах обработки данных стремились к децентрализованной архитектуре, масштабированию приложений и системной инфраструктуры в горизонтальном направлении. Эта тенденция, как правило, приводила к росту числа серверов. Со временем инфраструктура ЦОД становилась все более сложной, что сказывалось на возможности его модернизации, обслуживании, стоимости и пр. Централизованная архитектура может уменьшить количество серверов и увеличить степень использования оборудования при сравнимой производительности, а так же уменьшить стоимость владения оборудованием. 

`Частичная виртуализация` (нативная виртуализация) базируется на принципе эмуляции только необходимого количества ресурсов, чтобы виртуальная машина могла быть запущена изолировано. Например, при полной эмуляции различных архитектур, гостевая система работает с определенной специфической системой команд процессора, отличной от системы команд процессора хостовой системы. Каждую команду процессору гостевой системы нужно транслировать в соответствующую команду хостовой системы, что невероятно уменьшает быстродействие. При использовании нативной виртуализации никакой трансляции команд не происходит, так как гостевая операционная система разработана под ту же архитектуру, на которой работает хостовая система. Это позволяет значительно повысить быстродействие гостевой системы и максимально приблизить его к быстродействию реальной системы.
Для повышения быстродействия нативной виртуализации применяется специализированная программная прослойка – `гипервизор`. Гипервизор является посредником между гостевой операционной системой и физическим аппаратным обеспечением. Он позволяет гостевой системе напрямую обращаться к аппаратным ресурсам, что и является секретом высокого быстродействия данного вида виртуализации. Гипервизор является одним из ключевых понятий в мире виртуализации.

Частичная эмуляция является самым распространенным видом виртуализации в наше время. Основным ее недостатком является зависимость виртуальных машин от конкретной аппаратной архитектуры [3].
Примеры продуктов для частичной эмуляции: `VMware Workstation, VMware Server, VMware ESXI Server, Virtual Iron, Microsoft Hyper-V Server, Microsoft Virtual PC, Sun VirtualBox, Parallels Desktop` и другие.

В хакатоне мы будем использовать ЦОД под управлением гипервизора `ESXi 6.5` и платформы централизованного управления `VMware vCenter`. Вы можете ознакомиться с документацией по `VMware vCenter` [[тут]](https://docs.vmware.com/en/VMware-vSphere/index.html). В комплекте с `vCenter` предоставляется веб-клиент `VMware vSphere Web Client`, с помощью которого можно управлять виртуальной инфраструктурой через один из распространенных браузеров c поддержкой `Flash Player`).

Для выполнения заданий хакатона для каждой команды выделен пул виртуальных ресурсов:

- Оперативная память:  8 ГБ.

- Эквивалентная микропроцессорная частота: 2400 МГц.

- Объем дискового пространства 50 ГБ.


****
## Доступ к виртальному ЦОД <a name="21"></a>

Для доступа к выделенному для команды пула ресурсов необходимо открыть страницу по адресу:

* [https://195.19.40.127/vsphere-client/?csp](https://195.19.40.127/vsphere-client/?csp)

Для доступа необходимо использовать логин и пароль, предоставленные организаторами хакатона.

![Доступ к VMware vCenter](assets/vmware.png)
**Доступ к VMware vCenter**

После ввода логина и пароля вы на главную административную панель `VMware vSphere Web Client` (т.н. Home).

![](assets/esx_1.png)
**Главную административную панель `VMware vSphere Web Client`**

>При первом входе вам необходимо изменить пароль. 

>Войдите в меню **Roles -> Users and Groups**. Выберите в списке вашу команду (team), введите текущий пароль и дважды новый пароль. Требования к сложности пароля: только цифры, не менее 6 цифр.

![](assets/esx_2.png)

****
## Создание виртуальной машины и установка ОС <a name="22"></a>

> Перейдите из главной административной панели в раздел **Hosts and Clasters**.

Иерархия виртуального ЦОД сотсоит из следующих уровней:

1) Уровень Центра обработки данных: `195.19.40.127`

2) Уровен кластера: `IU6`

3) Уровень хоста: `195.19.40.124` или `195.19.40.125` или `195.19.40.126`. 

4) Уровень консолидированного вычислительного пула (так называемое виртуальное приложение `vAPP`): `team**`.

Дальнейшие действия необходимо производить только на уровне 4). Управление остальными уровнями иерархии выполняется только администратором ЦОД.

![](assets/esx_3.png)
**Иерархия виртуального ЦОД**

> Вызовите контекстное меню для вычислительного пула. Выберите пункт **New Virtual Machine**.

![](assets/esx_4.png)
**Создание новой виртуальной машины**

Далее соледуйте указаниям диалога. 

>В пункте **2a** выберите кластер для развертывания виртуальной машины: `IU6`. 

![](assets/esx_5.png)

>В пункте **2b** выберите вычислительный пул: `team**`. 

![](assets/esx_6.png)

>В диалоге выбора ресурсов виртуальной машины виберите следующие ресурсы:

>- 2 CPU

>- 8 GB RAM

>- 20 GB HDD. !!!По умолчанию выбирается так называемый Thin (тонкий) тип диска, позволяющий автоматически расширять дисковое пространство по мере заполнения диска. 

![](assets/esx_8.png)

>Для установки операционной системы необходимо подключить виртуальный привод CD/DVD и смонтировать в него зустановочный образ системы. Выберите пункт **Datastore ISO file**. В открывшемся диалоге выберите идин из образов CentOS в папке **OS_images**. Включите пункт **Connect** для CD/DVD.

!!! Рекомендуется использовать версию ОС Linux без установленного рабочего стола. Например: `CentOS-7-x86_64.Minimal-1810.iso`!!!

![](assets/esx_7.png)

>Проверьте параметры ВМ. Создайте виртуальную машину.

![](assets/esx_9.png)

Теперь необходимо установить операционную систему. 

>В контекстом меню ВМ выберите пункт **Power -> Power On**.

![](assets/esx_10.png)

Откройте консоль ВМ:

![](assets/esx_11.png)

>Установите ОС со следующими сетевыминастройками:

Сетевые настройки: 

    IP адрес: выдается организаторами из диапазона 195.19.36.64/27

    Шлюз: 195.19.36.65

    DNS: 195.19.32.2

![](assets/esx_12.png)




****
# Дополнительные источники <a name="a001"></a>

<a name="pub1">[1]</a> [Yuji Roh. A Survey on Data Collection for Machine Learning: a Big Data - AI Integration Perspective](https://arxiv.org/abs/1811.03402)

<a name="pub2">[2]</a> [Behera, Rabi. A Survey on Machine Learning: Concept, Algorithms and Applications](https://www.researchgate.net/publication/316273553_A_Survey_on_Machine_Learning_Concept_Algorithms_and_Applications)


