****
# Введение <a name="1"></a>

Благодаря достижениям в области искусственного интеллекта в последние годы открываются новые области применения методов и алгоритмов машинного обучения. В то время как проекты машинного обучения различаются по размеру и сложности, требуя различных навыков работы с данными, их общая структура как правило одинакова. Можно констатировать, что для получения хороших результатов анализа, важно иметь хорошо подобранные данные и команду экспертов, обладающую необходимыми навыками для управления проектом машинного обучения. В этом исследовании мы будем следовать конвейеру машинного обучения, состоящему из шести ступеней.

![Последовательность этапов конвейера машинного обучения](assets/ml_pipeline.png)
**Последовательность этапов конвейера машинного обучения**

Далее мы кратко опишем цели указанных этапов и алгоритмы, пименяемые для их реализации.

## Алгоритмы предварительной обработки данных <a name="1_1"></a>

Предварительная обработка данных - это методика анализа данных, которая включает в себя преобразование необработанных данных в понятный формат. Реальные данные часто являются неполными, непоследовательными и/или недостающими и могут содержать ошибки. Предварительная обработка данных осуществляется благодаря последовательному применению ряда алгоритмов для решения таких проблем. Поскольку подготовка данных всущественно влияет на результаты всего процесса машинного обучения, мы дадим краткое описание основных методов предварительной обработки данных, включая:

1) обработку пропущенных значений;

2) преобразование признаков, нормализацию и стандартизацию;

3) уменьшение размерности;

4) выбор признаков;

5) разделение данных.

Полученные от первоисточника числовые данные могут быть представлены в различной форме. Поэтому, сначала выполняется очистка данных, которая включает в себя обработку пропущенных значений и отбрасывание всех данных, которые имеют недостоверные значения или могут быть классифицированы как т.н. выбросы. Так как такой процесс требует глубокого знания предметной области, он должен выполняться совместно с прикладными специалистами. Например, искаженные значения могут быть вызваны сбоем в работе механизма, который сгенерировал набор данных, или лицом, ответственным за запись данных. Только специалисты с высоким уровнем знаний в предметной области могут определить, какие значения следует опускать, а какие показывают целесообразное измерение. Тщательный анализ первичных данных должен сопровождаться ведением протокола, отражающего внесенные изменения. Это может оказаться существенным при дальнейшем понимании результатов машинного обучения. Пропущенные значения обычно заменяются некоторыми правдоподобными значениями, такими как среднее или наиболее частое значение столбца. 

Далее принято производить масштабирование данных для каждого из призаков, чтобы поместить весь набор данных в один общий интервал. Очень важно, чтобы диапазон всех атрибутов был нормализован, чтобы каждый атрибут вносил одинаковый вклад в конечный результат [[1]](https://arxiv.org/abs/1811.03402). Тем не менее, это действие не должно влиять на тип категориальных атрибутов. Некоторыми популярными методами масштабирования являются: нормализация мин-макс, нормализация среднего значения, логарифмическое преобразование и стандартизация атрибутов.

Затем выполняется анализ и выбор наиболее существенных признаков. На данном этапе производится выбор наиболее важных признаков из всех имеющихся. Это можно сделать, извлекая новые признаки из имеющихся или удаляя признаки, которые не влияют на результат или добавляют шум.

Последний этап предварительной обработки данных, это разделение доступных данных на две части. Первая часть данных используется для создания модели (обучающая выборка), а другая - для оценки качества модели (тестовая выборка).

## Алгоритмы машинного обучения <a name="1_2"></a>

Выбор правильного алгоритма является ключевой частью любого проекта по машинному обучению, и, поскольку есть десятки вариантов на выбор, важно понять их сильные и слабые стороны в различных бизнес-приложениях [[2]](https://www.researchgate.net/publication/316273553_A_Survey_on_Machine_Learning_Concept_Algorithms_and_Applications). В этом курсе мы поговорим об алгоритмах в двух видах обучения: 

- Обучение с учителем, 
   
- Обучение без учителя.


### Обучение с учителем <a name="1_2_1"></a>

Алгоритмы контролируемого обучения строят математическую модель набора данных, который содержит как входы, так и желаемые результаты. Данные известны как данные обучения и состоят из набора обучающих примеров. Каждый обучающий пример имеет один или несколько входов и желаемый выход, также известный как контрольный сигнал. В случае полуобучаемых алгоритмов, обучения в некоторых учебных примерах отсутствует желаемый результат. В математической модели каждый обучающий пример представлен массивом или вектором, а обучающие данные матрицей. Посредством итеративной оптимизации целевой функции, алгоритмы обучения с учителем изучают функцию, которая может использоваться для прогнозирования результатов, связанных с новыми входными данными. Оптимальная функция позволит алгоритму правильно определять выходные данные для входов, которые не были частью обучающих данных. 

Говорят, что алгоритм, улучшающий точность результатов или прогнозов с течением времени, научился выполнять эту задачу. Алгоритмы обучения с учителем включают классификацию и регрессию. Алгоритмы классификации используются, когда выходные данные ограничены ограниченным набором значений, а алгоритмы регрессии используются, когда выходные данные могут иметь любое числовое значение в пределах диапазона. Обучение сходству является областью контролируемого машинного обучения, тесно связанной с регрессией и классификацией, но цель состоит в том, чтобы учиться на примерах с использованием функции сходства, которая измеряет, насколько похожи или связаны два объекта. Оно имеет приложения для ранжирования, системы рекомендаций, визуального отслеживания личности, проверки лица и проверки докладчика.

### Обучение без учителя <a name="1_2_2"></a>

Алгоритмы обучения без учителя берут набор данных, который содержит только входные данные, и находят структуру данных, такую ​​как группировка или кластеризация точек данных. Алгоритмы поэтому учатся на тестовых данных, которые не были помечены, классифицированы или классифицированы. Вместо того, чтобы реагировать на обратную связь, неконтролируемые алгоритмы обучения выявляют общие черты в данных и реагируют на основании наличия или отсутствия таких общих черт в каждом новом фрагменте данных. 

*Кластерный анализ* - это распределение набора наблюдений в подмножества (называемые кластерами), чтобы наблюдения в пределах одного кластера были похожи в соответствии с одним или несколькими заранее определенными критериями, в то время как наблюдения, полученные из разных кластеров, отличаются. Различные методы кластеризации делают разные предположения о структуре данных, часто определяемые некоторой метрикой сходства и оцениваемые, например, по внутренней компактности или сходству между членами одного кластера и различию - разнице между кластерами. Другие методы основаны на оценке плотности и связности графа.



****
## Типовая вычислительная инфраструктура для машинного обучения  <a name="1_3"></a>

В ходе выполнения конкурсных заданий и самостоятельной разработки конвейера машинного обучения мы предлагаем каждой команде развернуть набор средств для обработки тестовых данных.

Примером подобной системы является структура, представленная на следующем рисунке.

Каждая команда располагает следующими ресурсами для реализаци проектов машинного обучения.

Для выполнения заданий хакатона каждой команде предоставляется следующие вычислительные ресурсы:

- Пул ресурсов в ЦОД МГТУ им Баумана: 8 ГБ ОЗУ, 4 ядра микропроцессора 2400 МГц, 50 ГБ дискового пространства.
- Предоставляется ip адрес в DMZ МГТУ с открытыми портами.
- Допускается объединять ресурсы команд в кластеры (например, )
- Дополнительно команды могут использовать ресурсы облачной платформы `IBM Cloud`, которая может использоваться для реализации сервисов аналитической обработки и визуализации данных.  Для получения доступ к ресурсам IBM, необходимо использовать почтовый адрес из домена `student.bmstu.ru` или `bmstu.ru` при регистрации в программе Академической инициативе по адресу [ibm.biz/academic](ibm.biz/academic). Инструкция по получению почтового адрес из домена `student.bmstu.ru` находится [тут](https://mail.bmstu.ru/~postmaster/mail_for_students_and_aspirants.pdf).



****
## Проект хакатона <a name="1_4"></a>

Всем командам предлагается собрать template-проект, который может быть модифицирован командами для реализации собственных идей.
В проекте использовано следующие технологии:

-  Платформой виртуализации VMware vSphere 6.5
-  ОС Linux (Debian/Ubuntu/CentOS)
-  Anaconda/Jupyter Notebooks
-  Язык Python 3
-  IBM Cloud / Watson Studio
 

****
## Оборудование и настройка компьютера разработчика <a name="1_5"></a>

* Учатник хакатона может выполнить все задания, используя компьютер в аудитории МГТУ, однако рекомендуется использовать собственный ноутбук. Желательно использование операционной системы Linux (Ubuntu, Arch, CentOS, RHEL) или MacBook. В случае использования компьютера под управлением OC Windows рекомендуется воспользоваться готовым образом виртуальной машины, который можно найти на портале: [https://www.osboxes.org/ubuntu/](https://www.osboxes.org/ubuntu/).

****
# День 1. Управление виртуальным ЦОД <a name="2"></a>

Понятие виртуализации в широком смысле представляет собой сокрытие настоящей реализации какого-либо объекта или процесса от истинного его представления для пользователя. Результатом виртуализации является нечто удобное для использования, на самом деле, имеющее более сложную или совсем иную структуру, отличную от той, которая воспринимается при работе с объектом. Происходит отделение представления от реализации. В компьютерных технологиях под термином «виртуализация» обычно понимается абстракция вычислительных ресурсов (чаще всего серверов) и предоставление пользователю системы, которая «инкапсулирует» (скрывает в себе) собственную реализацию. Проще говоря, пользователь работает с удобным для себя представлением объекта, и для него не имеет значения, как объект устроен в действительности.

![Виртуальные машины, работающие на физическом оборудовании](assets/virtualisation.png)
**Виртуальные машины, работающие на физическом оборудовании**

Долгое время в центрах обработки данных стремились к децентрализованной архитектуре, масштабированию приложений и системной инфраструктуры в горизонтальном направлении. Эта тенденция, как правило, приводила к росту числа серверов. Со временем инфраструктура ЦОД становилась все более сложной, что сказывалось на возможности его модернизации, обслуживании, стоимости и пр. Централизованная архитектура может уменьшить количество серверов и увеличить степень использования оборудования при сравнимой производительности, а так же уменьшить стоимость владения оборудованием. 

`Частичная виртуализация` (нативная виртуализация) базируется на принципе эмуляции только необходимого количества ресурсов, чтобы виртуальная машина могла быть запущена изолировано. Например, при полной эмуляции различных архитектур, гостевая система работает с определенной специфической системой команд процессора, отличной от системы команд процессора хостовой системы. Каждую команду процессору гостевой системы нужно транслировать в соответствующую команду хостовой системы, что невероятно уменьшает быстродействие. При использовании нативной виртуализации никакой трансляции команд не происходит, так как гостевая операционная система разработана под ту же архитектуру, на которой работает хостовая система. Это позволяет значительно повысить быстродействие гостевой системы и максимально приблизить его к быстродействию реальной системы.
Для повышения быстродействия нативной виртуализации применяется специализированная программная прослойка – `гипервизор`. Гипервизор является посредником между гостевой операционной системой и физическим аппаратным обеспечением. Он позволяет гостевой системе напрямую обращаться к аппаратным ресурсам, что и является секретом высокого быстродействия данного вида виртуализации. Гипервизор является одним из ключевых понятий в мире виртуализации.

Частичная эмуляция является самым распространенным видом виртуализации в наше время. Основным ее недостатком является зависимость виртуальных машин от конкретной аппаратной архитектуры [3].
Примеры продуктов для частичной эмуляции: `VMware Workstation, VMware Server, VMware ESXI Server, Virtual Iron, Microsoft Hyper-V Server, Microsoft Virtual PC, Sun VirtualBox, Parallels Desktop` и другие.

В хакатоне мы будем использовать ЦОД под управлением гипервизора `ESXi 6.5` и платформы централизованного управления `VMware vCenter`. Вы можете ознакомиться с документацией по `VMware vCenter` [[тут]](https://docs.vmware.com/en/VMware-vSphere/index.html). В комплекте с `vCenter` предоставляется веб-клиент `VMware vSphere Web Client`, с помощью которого можно управлять виртуальной инфраструктурой через один из распространенных браузеров c поддержкой `Flash Player`).

Для выполнения заданий хакатона для каждой команды выделен пул виртуальных ресурсов:

- Оперативная память:  8 ГБ.

- Эквивалентная микропроцессорная частота: 2400 МГц.

- Объем дискового пространства 50 ГБ.


****
## Доступ к виртальному ЦОД <a name="21"></a>

Для доступа к выделенному для команды пула ресурсов необходимо открыть страницу по адресу:

* [https://195.19.40.127/vsphere-client/?csp](https://195.19.40.127/vsphere-client/?csp)

Для доступа необходимо использовать логин и пароль, предоставленные организаторами хакатона.

![Доступ к VMware vCenter](assets/vmware.png)
**Доступ к VMware vCenter**

После ввода логина и пароля вы на главную административную панель `VMware vSphere Web Client` (т.н. Home).

![](assets/esx_1.png)
**Главную административную панель `VMware vSphere Web Client`**

При первом входе вам необходимо изменить пароль. 

Войдите в меню **Roles -> Users and Groups**. Выберите в списке вашу команду (team), введите текущий пароль и дважды новый пароль. Требования к сложности пароля: только цифры, не менее 6 цифр.

![](assets/esx_2.png)

****
## Создание виртуальной машины и установка ОС <a name="22"></a>

Перейдите из главной административной панели в раздел **Hosts and Clasters**.

Иерархия виртуального ЦОД сотсоит из следующих уровней:

1) Уровень Центра обработки данных: `195.19.40.127`

2) Уровен кластера: `IU6`

3) Уровень хоста: `195.19.40.124` или `195.19.40.125` или `195.19.40.126`. 

4) Уровень консолидированного вычислительного пула (так называемое виртуальное приложение `vAPP`): `team**`.

Дальнейшие действия необходимо производить только на уровне 4). Управление остальными уровнями иерархии выполняется только администратором ЦОД.

![](assets/esx_3.png)
**Иерархия виртуального ЦОД**

Вызовите контекстное меню для вычислительного пула. Выберите пункт **New Virtual Machine**.

![](assets/esx_4.png)
**Создание новой виртуальной машины**

Далее соледуйте указаниям диалога. 

В пункте **2a** выберите кластер для развертывания виртуальной машины: `IU6`. 

![](assets/esx_5_u.png)

В пункте **2b** выберите вычислительный пул: `team**`. 

![](assets/esx_6.png)

В диалоге выбора ресурсов виртуальной машины виберите следующие ресурсы:

- 2 CPU

- 8 GB RAM

- 20 GB HDD. 

![](assets/esx_8.png)

!!!По умолчанию выбирается так называемый Thick (толстый) тип диска. Все пространство такого диска выделяется в момент создания, при этом блоки не очищаются от данных, которые находились там ранее. Это может создавать потенциальные угрозы безопасности, поскольку виртуальная машина может получить доступ к данным на хранилище VMFS, которые ей не принадлежат. При обращении к блокам такого диска их содержимое предварительно не очищается со стороны ESX. Преимущество дисков типа thick - производительность и быстрота создания, недостаток - безопасность

Поэтому мы будем использовать диски типа Thin ("тонкие диски"), позволяющий автоматически расширять занимаемое дисковое пространство по мере заполнения диска. 
Эти диски создаются минимального размера и растут по мере их наполнения данными до выделенного объема. При выделении нового блока - он предварительно очищается. Эти диски наименее производительны (выделение нового блока и его очистка), однако наиболее оптимальны для экономии дискового пространства на системе хранения данных.

![](assets/esx_8_1.png)


Для установки операционной системы необходимо подключить виртуальный привод CD/DVD и смонтировать в него зустановочный образ системы. Выберите пункт **Datastore ISO file**. В открывшемся диалоге выберите идин из образов Ubuntu в папке **OS_images**. Включите пункт **Connect** для CD/DVD.

!!! Рекомендуется использовать версию ОС Linux без установленного рабочего стола. Например: `Ubuntu-18.04.3-live-server-amd64.iso`!!!


![](assets/esx_7_u.png)

Проверьте параметры ВМ. Создайте виртуальную машину.

![](assets/esx_9.png)

Теперь необходимо установить операционную систему. 

В контекстом меню ВМ выберите пункт **Power -> Power On**.

![](assets/esx_10.png)

Откройте консоль ВМ:

![](assets/esx_11.png)

Установите ОС со следующими сетевыми настройками:

Сетевые настройки: 

    IP адрес: выдается организаторами из диапазона 195.19.36.64/27

    Шлюз: 195.19.36.65

    DNS: 195.19.32.2

![](assets/esx_12_u.png)

При установке серверной версии ОС Ubuntu обязательно разрешите использование LVM (Logical Volume Manager), что позволит расширять объем логических томов в процессе работы Linux.

![](assets/esx_13_u.png)

Разрешите установку и запуск OpenSSH сервера, что понадобится для соединения с Вашей виртуальной системой по протоколу SSH.

![](assets/esx_14_u.png)

После установки системы перегрузите виртуальную машину и выполните вход по введенным вами реквизитам пользователя.

![](assets/esx_15_u.png)

Проверьте, что сетевое соединение работает:

    ping www.ya.ru

Если соединение отсуствует, отредактируйте файл /etc/netplan/50-cloud-init.yaml. После этого актуализируйте конфигурацию сети по команде:

    sudo netplan apply

Используя терминал операционной системы можно выполнить пинг вашей системы:

    ping 195.19.36.66

    PING 195.19.36.66 (195.19.36.66) 56(84) bytes of data.

    64 bytes from 195.19.36.66: icmp_seq=1 ttl=58 time=5.94 ms

    64 bytes from 195.19.36.66: icmp_seq=2 ttl=58 time=5.79 ms


Если ваша система успешно пингуется, то можно подключиться к ней используя терминал с поддержкой протокола SSH (Tilix, Putty, term и пр.).
В ОС Linux это можно сделать по команде:

    ssh username@ip_address



![](assets/esx_16.png)

****
## Уcтановка фреймворка Anaconda и Jupyter Notebooks <a name="23"></a>


Anaconda Distribution это фреймворк с открытым исходным кодом, который объединяет библиотеки и средства разработки кода на языках Python / R для решения задач в области машинного обучения и науки о данных. Anaconda доступна как в виде десктопного приложения на платформах Linux, Windows и Mac OS X, так и в составе серверного ПО. В состав дистрибутива входит более 1500 пакетов Python / R для научных исследований, средста управления бибилиотеками Conda, средства разработки  обучения моделей машинного обучения и глубокого обучения scikit-learn, TensorFlow и Theano, известные бибилотеки для анализа данных (Dask, NumPy, pandas и Numba и т.д.) и визуализации результатов (Matplotlib, Bokeh, Datashader, Holoviews и пр.)


Подготовим виртуальную машину к установке дистрибутива. Необходимо по крайней мере 2 ГБ свободного места на жестком диске в томе **/**. Проверим это: 

    df -h

    Filesystem                         Size  Used Avail Use% Mounted on

    udev                               463M     0  463M   0% /dev

    tmpfs                               99M  1.1M   98M   2% /run

    **/dev/mapper/ubuntu--vg-ubuntu--lv  3.9G  3.7G     0 100% /**

    tmpfs                              493M     0  493M   0% /dev/shm

    tmpfs                              5.0M     0  5.0M   0% /run/lock

    tmpfs                              493M     0  493M   0% /sys/fs/cgroup

    /dev/loop0                          89M   89M     0 100% /snap/core/7270

    /dev/sda2                          976M   76M  834M   9% /boot

    tmpfs                               99M     0   99M   0% /run/user/1000


Место, выделенное на диске во время установки системы явно недостаточно. Так как мы использовали `LVM`, нам необходимо расширить логиский том за счет имеющегося свободного пространства на диске. Выведем список логических томов:

    sudo lvdisplay

    --- Logical volume ---

    LV Path                **/dev/ubuntu-vg/ubuntu-lv**

    LV Name                ubuntu-lv

    VG Name                **ubuntu-vg**

    LV UUID                nZSozr-hX7F-foyY-op40-8uKp-IYL9-wLplX0

    LV Write Access        read/write

    LV Creation host, time ubuntu-server, 2019-09-29 15:54:06 +0000

    LV Status              available

    # open                 1

    LV Size                4.00 GiB

    Current LE             1024

    Segments               1

    Allocation             inherit

    Read ahead sectors     auto

    - currently set to     256

    Block device           253:0

В отчете указано, что логический том размещен в группе физических томов **ubuntu-vg**, где мы и будем выделять пространство. Уточним, есть ли свободное место в **ubuntu-vg**:

    sudo vgdisplay

    --- Volume group ---

    VG Name               ubuntu-vg

    System ID             

    Format                lvm2

    Metadata Areas        1

    Metadata Sequence No  3

    VG Access             read/write

    VG Status             resizable

    MAX LV                0

    Cur LV                1

    Open LV               1

    Max PV                0

    Cur PV                1

    Act PV                1

    VG Size               <49.00 GiB

    PE Size               4.00 MiB

    Total PE              12543

    Alloc PE / Size       1024 / 3.70 GiB

    Free  PE / Size       11519 / 46.30 GiB

    VG UUID               dvjRPM-MLcl-QsFw-sXPp-72CA-mZpy-Oeb3fy


Также можно узнать, на каком из физических дисков емеется свободное пространство (т.к. у нас только один диск, показан будет он)

    sudo pvdisplay

    --- Physical volume ---

    PV Name               /dev/sda3

    VG Name               ubuntu-vg

    PV Size               &lt;49.00 GiB / not usable 0   

    Allocatable           yes 

    PE Size               4.00 MiB

    Total PE              12543

    Free PE               1024

    Allocated PE          11519

    PV UUID               Z1Ya4U-czwy-37JR-DAYw-SDTm-v9JI-oP3zCT


В отчете lvdisplay указан системный путь к логическому устройству тома: **/dev/ubuntu-vg/ubuntu-lv**. Расширим его на 2048 блоков по 4 MiB: 


    sudo lvextend -l +2048 /dev/ubuntu-vg/ubuntu-lv

    sudo resize2fs /dev/ubuntu-vg/ubuntu-lv 

    sudo lvdisplay

    --- Logical volume ---

    LV Path                /dev/ubuntu-vg/ubuntu-lv

    LV Name                ubuntu-lv

    VG Name                ubuntu-vg

    LV UUID                nZSozr-hX7F-foyY-op40-8uKp-IYL9-wLplX0

    LV Write Access        read/write

    LV Creation host, time ubuntu-server, 2019-09-29 15:54:06 +0000

    LV Status              available

    \# open                 1

    LV Size                **12.00 GiB**

    Current LE             3072

    Segments               1

    Allocation             inherit

    Read ahead sectors     auto

    - currently set to     256

    Block device           253:0


Далее уточним состояние логического тома:

    df -h

    Filesystem                         Size  Used Avail Use% Mounted on

    udev                               463M     0  463M   0% /dev

    tmpfs                               99M  1.1M   98M   2% /run

    **/dev/mapper/ubuntu--vg-ubuntu--lv   12G  3.7G   8G  30% /**

    tmpfs                              493M     0  493M   0% /dev/shm

    tmpfs                              5.0M     0  5.0M   0% /run/lock

    tmpfs                              493M     0  493M   0% /sys/fs/cgroup

    /dev/loop0                          89M   89M     0 100% /snap/core/7270

    /dev/sda2                          976M   76M  834M   9% /boot

    tmpfs                               99M     0   99M   0% /run/user/1000


Теперь места на диске достаточно, начнем установку Anaconda. Установим дистрибутив в домашней директории пользователя виртуальной машины:

    cd ~

    wget https://repo.anaconda.com/archive/Anaconda3-2019.03-Linux-x86_64.sh
    
    chmod +x Anaconda3-2019.03-Linux-x86_64.sh

    bash ./Anaconda3-2019.03-Linux-x86_64.sh

Проверим список установленных пакетов:

    conda list

Обновим устаревшие пакеты:

    conda update conda

Теперь необходимо настроить Jupyter Notebook. Сгенерируем шаблон конфигурационного файла:

    jupyter notebook --generate-config

Теперь добавим в конфигурационный файл, указанный при создании (`~/.jupyter/jupyter_notebook_config.py`) следующие строки:


    /# Разрешим доступ из внешней сети

    c.NotebookApp.ip = 'ip адрес вашего сервера'

    c.NotebookApp.open_browser = False

    /# Укажем порт, на котором будет работать Jupyter Notebook

    c.NotebookApp.port = 8888

Далее создадим файл с хешированным паролем:

    jupyter notebook password


Теперь все готово для запуска Jupyter Notebook. Вы можете сделать это в консоли по команде:


    jupyter notebook &

    или

    jupyter lab &

    если вы не хотите читать лог приложения в консоли, вы можете перенаправить поток сообщений на устройство /dev/null:

    jupyter notebook >/dev/null 2>&1

Теперь вы можете подключиться к Jupyter Notebook в броузере по адресу:    

    http://<ip адрес вашего сервера>:8888/



****
# Дополнительные источники <a name="a001"></a>

<a name="pub1">[1]</a> [Yuji Roh. A Survey on Data Collection for Machine Learning: a Big Data - AI Integration Perspective](https://arxiv.org/abs/1811.03402)

<a name="pub2">[2]</a> [Behera, Rabi. A Survey on Machine Learning: Concept, Algorithms and Applications](https://www.researchgate.net/publication/316273553_A_Survey_on_Machine_Learning_Concept_Algorithms_and_Applications)


