****
# День 3. Алгоритмы машинного обучения <a name="4"></a>

## Методология машинного обучения <a name="4_1"></a>

Существует мнение о том, что не существует единого метода машинного обучения, который лучше всего справлялся бы со всеми проблемами. Независимо от того, насколько сложный или простой метод, он не будет работать наилучшим образом для всех проблем. 

Поэтому, чтобы найти лучший метод и его алгоритмическую реализацию, которые соответствуют потребностям конкретной задачи, необходимо обладать кругозором и владеть программными средствами для реализации алгоритмов анализа данных.  

Считается, что прежде чем углубляться в сложные методы и тратить время на тонкую настройку модели, лучше попробовать более простые методы и алгоритмы. По мере продвижения к более сложным методам мы можем обнаружить, что для наших нужд оказывается достаточно уже примененнного и более простого подхода.

Гибкая методология машинного обучения предполагают, что мы должны развивать понимание данных итерационно. Это означает, что мы не должны пытаться разрешить все проблемы сразу. Для науки о данных это означает, что мы начинаем с простого подхода и готовимся к применению более сложных методов и методик. Первая итерация должна иметь наиболее простой вариант реализации каждого этапа конвейера машинного обучения(например, обработка, извлечение признаков и пр.). Дополнительным достоинством такого подхода является то, что применение упрощенных подходов менее затратно с точки зрения вычислительной мощьности, не требует интенсивных вычислений или дорогих поисков гиперпараметров. Бесспорно, простая модель может работать плохо, но получение этой модели возможно максимально быстро и с минимальными затратами ресурсов. 

Пример такого простого метода: поиск ближайшего соседа и другие подобные методы. Для их реализации требуется лишь несколько строк кода. Вместе с тем нет никаких причин, по которым более простые методы не могут быть лучше сложных. 

На последующих итерациях конверйера машинного обучения исследуются другие подходы. Это позволит нам сравнить, как методологические изменения влияют на производительность, и отслеживать улучшения с течением времени. Тем не менее, по мере дальнейших исследований улучшение качества модели становится все более проблематичным. Например, если мы достигли точности 99%, возможно, нам не следует тратить больше времени и ресурсов, чтобы пробовать доводить ее до 99,2%. 


### Предварительная обработка данных <a name="4_1_1"></a>


Целью предварительной обработки является преобразование необработанных данных в форму, которая подходит для машинного обучения. Структурированные и чистые данные позволяют получать более точные результаты из прикладной модели машинного обучения. Включает форматирование данных, очистку и выборку. Этот этап может также включать в себя сокращение числа несвязанных признаков с помощью разработки признаков, если у нас есть люди, которые могут это сделать (для этого требуются расширенные знания предметной области). Это будет важно, чтобы уменьшить сложность моделей.


#### Очистка данных <a name="4_1_1_1"></a>

*Очистка данных*, это набор процедур позволяет удалить шум и устранить несоответствия в данных. Это включает в себя заполнение недостающих данных с использованием методов вменения, например, замена отсутствующих значений на средние или максимальные частые значения. Обнаружение выбросов также важно (наблюдения, которые значительно отличаются от остальной части распределения). Если какие-либо выбросы указывают на ошибочные данные, их следует удалить или исправить, если это возможно. Этот этап также включает в себя удаление неполных и бесполезных записей данных и столбцов.


#### Масштабирования <a name="4_1_1_2"></a>

*Масштабирования* – данные могут иметь числовые атрибуты (признакы), которые охватывают различные диапазоны, например, миллиметры, метры и километры. Масштабирование - это преобразование этих атрибутов, чтобы они имели одинаковый масштаб, например, от 0 до 1 или от 1 до 10 для наименьшего и наибольшего значения для атрибута. 

*Мин-макс* нормализация вычитает минимальное значение в объекте, а затем делит на диапазон объекта. Он сохраняет исходное распределение функции и не вносит существенных изменений в информацию, встроенную в исходные данные. С другой стороны, стандартизация признака стандартизирует признак путем вычитания среднего значения, а затем деления на стандартное отклонение. Это изменяет распределение признаков и приводит к распределению со средним значением, равным нулю, и стандартным отклонением, равным единице. 

*Логарифмическое преобразование* важно для преобразования мультипликативных отношений между признаками в аддитивные отношения. Так как большие значения уменьшаются больше, чем маленькие, логарифмическое преобразование имеет эффект псевдоскейлинга, поскольку различия между большими и малыми значениями в наборе данных уменьшаются. 

Выбор одного метода масштабирования среди других зависит не только от набора данных, но и от выбранного метода машинного обучения, поскольку различные методы машинного обучения фокусируются на разных аспектах данных. Например, метод кластеризации фокусируется на анализе сходства точек данных, в то время как анализ главных компонентов объясняет как можно больше вариаций данных с минимально возможным количеством компонентов. Использование одного метода масштабирования может улучшить результаты кластеризации, скрывая результаты анализа PCA.


#### Уменьшение размерности<a name="4_1_1_3"></a>

*Уменьшение размерности* (Dimesion Reduction) – основная проблема при интерпретации многомерных данных заключается в том, что соответствующие, истинные сигналы скрыты нерелевантными данными или шумом. Для данных низкого и среднего размера можно использовать несколько классических статистических методов, которые фокусируются на идентификации сильных, истинных сигналов. Такие методы, однако, не могут быть распространены на случаи, когда размерность данных намного превышает размер записей, а слабые истинные сигналы окружены значительным количеством шума (как в случае современного геномного анализа). Кроме того, диапазон шума имеет тенденцию увеличиваться с увеличением размерности данных, что часто делает существующие методы непрактичными [3]. По мере роста количества признаков или измерений объем данных, которые нам необходимы для точного обобщения, растет в геометрической прогрессии.

При добавлении нового признака в модель иногда не хватает данных для поддержания отношений, и, следовательно, новый признак может не иметь положительное влияние на модель. Поэтому мы заканчиваем тем, что делаем его более сложным, не используя его в своих интересах. Например, в нашем исследовании мы имеем 299 переменных (p = 299). В этом случае мы можем иметь 299 (299-1) / 2 = 44551 разных участков. Нет смысла визуализировать каждый из них в отдельности, верно? В тех случаях, когда у нас большое количество переменных, лучше выбрать подмножество этих переменных (p << 100), которое собирает столько информации, сколько и исходный набор переменных. Вот некоторые преимущества применения уменьшения размерности к набору данных:

• пространство, необходимое для хранения данных, уменьшается по мере уменьшения количества измерений,

• меньше размеров приводит к меньшему времени вычислений / обучения,

• некоторые алгоритмы не работают хорошо, когда у нас большие размеры. Таким образом, чтобы эти алгоритмы были полезны, необходимо уменьшить эти размеры,

• он заботится о мультиколлинеарности, удаляя лишние признакы. Например, у вас есть две переменные - «время, проведенное на беговой дорожке в минутах» и «сожженные калории». Эти переменные сильно коррелируют: чем больше времени вы проводите на беговой дорожке, тем больше калорий вы будете сжигать. Следовательно, нет смысла хранить оба, так как только один из них делает то, что нужно,

• это помогает в визуализации данных. Как обсуждалось ранее, очень трудно визуализировать данные в более высоких измерениях, поэтому сокращение нашего пространства до 2D или 3D может позволить нам более четко отображать и наблюдать шаблоны.

Уменьшение размерности может быть сделано двумя различными способами:

• выбор признаков: сохраняются только самые важные переменные из исходного набора данных,

• уменьшение размерности : путем нахождения меньшего набора новых переменных, каждая из которых является комбинацией входных переменных, содержащих в основном ту же информацию, что и входные переменные.


#### Алгоритм выбора признаков<a name="4_1_1_4"></a>

*Алгоритм выбора признаков* – один из наиболее широко используемых алгоритмов выбора объектов. Это помогает выбрать меньшее подмножество признаков. Причина в том, что древовидные стратегии, используемые случайными лесами, естественным образом ранжируются по тому, насколько хорошо они улучшают чистоту узла. Это означает уменьшение примесей по всем деревьям (так называемая примесь Джини). Узлы с наибольшим уменьшением примесей происходят в начале деревьев, тогда как примечания с наименьшим уменьшением примесей происходят в конце деревьев. Таким образом, обрезая деревья ниже определенного узла, мы можем создать подмножество наиболее важных функций. Случайный лес состоит из нескольких деревьев решений. Каждый узел в деревьях решений является условием для отдельного объекта, предназначенного для разделения набора данных на два, так чтобы одинаковые значения ответов оказались в одном наборе. Мера, на основе которой выбирается (локально) оптимальное условие, называется примесью.


#### Обратное удаление признаков<a name="4_1_1_5"></a>

*Обратное удаление признаков* (Backward Feature Elimination) -Удаление признаков рекурсивно удаляет признакы, строит модель с использованием оставшихся признаков и вычисляет точность модели. Он включает в себя следующие этапы:


1) сначала мы берем все «n» переменных, присутствующих в нашем наборе данных, и обучаем модель, используя их,

2) затем мы рассчитываем производительность модели,

3) теперь мы вычисляем производительность модели после исключения каждой переменной (n раз), то есть каждый раз отбрасываем одну переменную и обучаем модель оставшимся «n-1» переменным,

4)  мы определяем переменную, удаление которой дало наименьшее (или нет) изменение производительности модели, а затем отбрасываем эту переменную,

5) повторям этот процесс, пока ни одна переменная не может быть отброшена.

Нам нужно указать алгоритм и количество объектов, которые нужно выбрать, и мы вернемся к списку переменных, полученных при удалении объектов назад. Мы также можем проверить ранжирование переменных.


#### Выбор вперед<a name="4_1_1_6"></a>

*Выбор вперед* (Forward Feature Elimination) - Это противоположный процесс обратного удаления признаков, который мы видели выше. Вместо того, чтобы исключать признакы, мы пытаемся найти лучшие признакы, которые улучшают производительность модели. Эта техника работает следующим образом:

1) мы начинаем с одной функции. По сути, мы обучаем модель «n» раз, используя каждый признак отдельно,

2) переменная, дающая наилучшую производительность, выбирается в качестве начальной переменной,

3) затем мы повторяем этот процесс и добавляем одну переменную за раз,

4) переменная, которая дает наибольшее увеличение производительности, сохраняется,

5) мы повторяем этот процесс до тех пор, пока не будут замечены значительные улучшения в производительности модели.

ПРИМЕЧАНИЕ. Как обратное удаление, так и прямой выбор функций требуют много времени и вычислительных затрат.


#### Анализ главных компонентов<a name="4_1_1_7"></a>

*Анализ главных компонентов* (Principal Component Analysis) PCA, это методика, которая помогает нам извлекать новый набор переменных из существующего большого набора переменных. 

Эти вновь извлеченные переменные называются главными компонентами. Вот некоторые из ключевых моментов, которые следует знать о PCA:

1) главный компонент представляет собой линейную комбинацию исходных переменных,

2) основные компоненты извлекаются таким образом, что первый основной компонент объясняет максимальную дисперсию в наборе данных,

3) второй основной компонент пытается объяснить оставшуюся дисперсию в наборе данных и не связан с первым главным компонентом,

4) каждое дополнительное измерение, которое мы добавляем к методике PCA, отражает все меньше и меньше дисперсии в модели. Первый компонент является наиболее важным, затем следует второй, затем третий и т. д.

5) чтобы найти каждый компонент, алгоритм пытается максимизировать дисперсию, и каждый новый компонент должен быть ортогональным к другим.

Максимизирует дисперсию: определяет направление / размер максимальной дисперсии данных.
Ортогональный: находит направления, которые ортогональны (перпендикулярно первому найденному компоненту).

![](assets/ml_01.png)
**Анализ главных компонентов**

Слева мы имеем представление простого двумерного набора данных с тремя одномерными гиперплоскостями. С другой стороны, справа показан результат проецирования набора данных на каждую из этих одномерных гиперплоскостей. Глядя на эти три, становится ясно, что гиперплоскость, представленная сплошной линией, является той, которая максимизирует дисперсию по желанию. Поэтому сплошная линия является наиболее разумным выбором для более низкого измерения. Он также находит вторую ось (пунктирную линию), ортогональную первой, которая учитывает наибольшее количество оставшихся отклонений данных.

Если бы мы имели дело с более высокими измерениями, PCA нашел бы более ортогональную ось к предыдущим осям; столько осей, сколько число измерений в наборе данных. Единичный вектор, который определяет i-ю ось, называется главным компонентом (PC). В этом случае первый PC - это С1, а второй PC - С2.
после того, как мы определили наши основные компоненты, пришло время уменьшить размерность набора данных до d измерений, проецируя его на гиперплоскость, определенную первыми d основными компонентами.
Обычно большое количество измерений, это то, что составляет достаточно большую часть дисперсии (~ 90%).


#### Независимый компонентный анализ<a name="4_1_1_8"></a>


*Независимый компонентный анализ* (Independent Component Analysis) ICA - основан на теории информации, а также является одним из наиболее широко используемых методов уменьшения размерности. Основное различие между PCA и ICA состоит в том, что PCA ищет некоррелированные факторы, в то время как ICA ищет независимые факторы.
Если две переменные некоррелированы, это означает, что между ними нет линейной зависимости. Если они независимы, это означает, что они не зависят от других переменных. Например, возраст человека не зависит от того, что он ест, или от того, сколько он смотрит телевизор.

Этот алгоритм предполагает, что данные переменные представляют собой линейные смеси некоторых неизвестных скрытых переменных. Также предполагается, что эти скрытые переменные являются взаимно независимыми, то есть они не зависят от других переменных и, следовательно, их называют независимыми компонентами наблюдаемых данных.

#### Факторный анализ<a name="4_1_1_9"></a>


*Факторный анализ* (Factor Analysis) –  предположим, у нас есть две переменные: доход и образование. Эти переменные потенциально могут иметь высокую корреляцию, поскольку люди с более высоким уровнем образования, как правило, имеют значительно более высокий доход, и наоборот.
В методе факторного анализа переменные сгруппированы по их корреляциям, то есть все переменные в определенной группе будут иметь высокую корреляцию между собой, но низкую корреляцию с переменными другой группы (групп). Здесь каждая группа известна как фактор. Эти факторы невелики по сравнению с исходными размерами данных. Однако эти факторы трудно наблюдать.


#### Многообразное обучение или нелинейное уменьшение размерности<a name="4_1_1_10"></a>


*Многообразное обучение или нелинейное уменьшение размерности* (Manifold Learning) –  это как нелинейная версия PCA. PCA ищет плоские поверхности для описания данных. Если плоской поверхности не существует, мы используем Mainfold Learning, чтобы попытаться решить эту проблему более эффективно.
Существует много подходов для решения этой проблемы, таких как Isomap, Локально линейное вложение, Лапласово собственное отображение, Полуопределенное вложение и т. Д. Эти алгоритмы работают для извлечения низкоразмерного многообразия, которое можно использовать для описания многомерных данных.


#### Локально линейное вложение<a name="4_1_1_11"></a>

*Локально линейное вложение* (LLE) –  это метод коллективного обучения, который не опирается на такие проекции, как PCA. Он работает, изучая, как каждое наблюдение линейно связано с его ближайшими соседями, а затем ищет низкоразмерное представление обучающего набора, где эти отношения лучше всего сохраняются. Для случаев, когда нет большого шума, он очень хорош при развертывании скрученных коллекторов.
t- распределенное стохастическое вложение соседей (t-SNE t- Distributed Stochastic Neighbor Embedding) –  t-SNE ищет шаблоны нелинейным способом. t-SNE - это один из немногих алгоритмов, который способен одновременно сохранять как локальную, так и глобальную структуру данных. Он рассчитывает вероятностное сходство точек в многомерном пространстве, а также в низкоразмерном пространстве. Эвклидовы расстояния больших размеров между точками данных преобразуются в условные вероятности, которые представляют сходства.
UMAP –  t-SNE очень хорошо работает с большими наборами данных, но также имеет свои ограничения, такие как потеря крупномасштабной информации, медленное время вычислений и неспособность осмысленно представлять очень большие наборы данных. 

#### Унифицированная аппроксимация и проекция многообразия<a name="4_1_1_12"></a>

*Унифицированная аппроксимация и проекция многообразия* (UMAP) - это метод сокращения размеров, который может сохранить как большую часть локальной, так и большей глобальной структуры данных по сравнению с t-SNE, с более коротким временем выполнения. 

Некоторые из ключевых преимуществ UMAP:

• он может обрабатывать большие наборы данных и данных большого размера без особых проблем,

• он сочетает в себе возможности визуализации с возможностью уменьшения размеров данных,

• наряду с сохранением локальной структуры, он также сохраняет глобальную структуру данных. UMAP отображает близкие точки на многообразии в соседние точки в низкоразмерном представлении и делает то же самое для удаленных точек,

• этот метод использует концепцию k-ближайшего соседа и оптимизирует результаты с использованием стохастического градиентного спуска. Сначала он вычисляет расстояние между точками в многомерном пространстве, проецирует их на низкоразмерное пространство и вычисляет расстояние между точками в этом низкоразмерном пространстве. Затем он использует Stochastic Gradient Descent, чтобы минимизировать разницу между этими расстояниями.

Корреляция между компонентами, полученными из UMAP, значительно меньше по сравнению с корреляцией между компонентами, полученными из t-SNE. Следовательно, UMAP имеет тенденцию давать лучшие результаты.
Краткое описание того, когда использовать каждую методику уменьшения размерности

Кратко подведем итоги использования каждого метода уменьшения размерности, который мы рассмотрели. Важно понимать, где использовать определенную технику, поскольку это помогает сэкономить время, усилия и вычислительные мощности.

![](assets/ml_02.png)
**Использование методов уменьшения размерности**


#### Соотношение пропущенных значений<a name="4_1_1_13"></a>

Если в наборе данных слишком много пропущенных значений, мы используем этот подход для уменьшения количества переменных. Мы можем отбросить переменные с большим количеством пропущенных значений.

#### Фильтр низкой дисперсии<a name="4_1_1_14"></a>

Мы применяем этот подход для определения и удаления постоянных переменных из набора данных. На целевую переменную не влияют чрезмерно переменные с низкой дисперсией, и, следовательно, эти переменные могут быть безопасно отброшены

#### Фильтр высокой корреляции<a name="4_1_1_15"></a>

Пара переменных, имеющих высокую корреляцию, увеличивает мультиколлинеарность в наборе данных. Таким образом, мы можем использовать эту технику, чтобы найти сильно коррелированные функции и отбросить их соответственно.

#### Случайный лес<a name="4_1_1_16"></a>

Это один из наиболее часто используемых методов, который говорит нам о важности каждого атрибута, присутствующего в наборе данных. Мы можем найти важность каждого атрибута и сохранить самые верхние атрибуты, что приведет к уменьшению размерности. Как методы обратного удаления, так и прямого выбора элементов занимают много вычислительного времени и поэтому обычно используются в небольших наборах данных.

#### Факторный анализ<a name="4_1_1_17"></a>

Этот метод лучше всего подходит для ситуаций, когда у нас есть сильно коррелированный набор переменных. Он делит переменные на основе их соотношения на разные группы и представляет каждую группу с коэффициентом

#### Анализ основных компонентов<a name="4_1_1_18"></a>

Это один из наиболее широко используемых методов работы с линейными данными. Он делит данные на набор компонентов, которые пытаются объяснить как можно больше различий
Независимый анализ компонентов: мы можем использовать ICA для преобразования данных в независимые компоненты, которые описывают данные с использованием меньшего количества компонентов

- ISOMAP: мы используем эту технику, когда данные сильно нелинейны;

- t-SNE: этот метод также хорошо работает, когда данные сильно нелинейны или же требуется более понятная визуализаци данных.

- UMAP: эта методика хорошо работает для многомерных данных. Время его выполнения короче по сравнению с t-SNE.

#### Разделение набора данных<a name="4_1_1_19"></a>

**Разделение набора данных** (Dataset splitting) – набор данных, используемый для машинного обучения, должен быть разделен на три подмножества - наборы обучения, тестирования и проверки.

**Обучающий набор**: используется для обучения модели и определения ее оптимальных параметров - параметров, которые он должен изучить из данных.

**Тестовый набор**: тестовый набор необходим для оценки обученной модели и ее способности к обобщению. Обобщение означает способность модели идентифицировать закономерности в новых невидимых данных после того, как они прошли обучение по данным обучения. Крайне важно использовать различные подмножества для обучения и тестирования, чтобы избежать переобучения модели, что является неспособностью к обобщению, о котором мы упоминали выше.

**Набор проверки**: цель набора проверки состоит в том, чтобы настроить гиперпараметры модели - структурные параметры более высокого уровня, которые не могут быть непосредственно изучены из данных. Эти параметры могут указывать, например, насколько сложна модель и как быстро она находит шаблоны в данных.

Соотношение обучения и тестового набора обычно составляет 80 процентов. Затем обучающий набор снова разделяется, и его 20 процентов будут использоваться для формирования проверочного набора.
Чем больше используемых данных обучения, тем лучше будет работать потенциальная модель. Следовательно, больше используемых данных тестирования приводит к лучшей производительности модели и возможности обобщения.




### Алгоритмы машинного обучения <a name="4_1_2"></a>

После того, как мы предварительно обработали собранные данные и разбили их на три подмножества, мы приступаем к обучению модели. Этот процесс влечет за собой снабжение алгоритма данными обучения. Затем алгоритм обрабатывает данные и выводит модель, которая может найти целевое значение (атрибут) в новых данных (ответ, который мы хотим получить с помощью прогнозного анализа). Целью обучения модели является разработка модели.

Наиболее распространены два модельных стиля обучения - обучение с учителем и обучение без учителя. Выбор каждого стиля зависит от того, должны ли мы прогнозировать конкретные атрибуты или группировать объекты данных по сходству.

• *обучение с учителем*: Контролируемое обучение позволяет обрабатывать данные с целевыми атрибутами или помеченными данными. Обучение с учителем решает проблемы классификации и регрессии.

• *обучение без учителя*: Во время этого стиля обучения алгоритм анализирует немеченые данные. Цель обучения модели - найти скрытые взаимосвязи между объектами данных и объектами структуры по сходствам или различиям. Обучение без учителя направлено на решение таких проблем, как кластеризация, обучение правилам ассоциаций и уменьшение размерности. Например, его можно применять на этапе предварительной обработки данных, чтобы уменьшить сложность данных.

Существует два других стиля обучения модели: *полу-контролируемый*, в котором набор данных содержит как помеченные, так и немаркированные примеры. Второй стиль назвается *обучение с подкреплением*, при котором машина пытается выучить политику действий в соответствии с получением вознаграждения за каждое действие.
Мы опишем алгоритмы, которые являются не только самыми известными, но и либо очень эффективными сами по себе, либо используются в качестве строительных блоков для самых эффективных алгоритмов обучения.


![](assets/ml_03.png)
**Алгоритмы машинного обучения**

####  Линейная регрессия<a name="4_1_2_1"></a>

Линейная регрессия –  это популярный алгоритм обучения регрессии, который изучает модель, представляющую собой линейную комбинацию атрибутов входного примера.
Мы хотим построить модель  как линейную комбинацию признаков из примера :



где 	 – это D-мерный вектор параметров,
 - это реальное число. 
Обозначения  означают, что модель параметризована двумя значениями: 
Мы хотим найти оптимальные значения . Оптимальные значения параметров определяют модель, которая делает наиболее точные прогнозы.
Цель алгоритма – построить гиперплоскость, максимально приближенную ко всем обучающим примерам (Рисунок 13).


![](assets/ml_04.png)
**Линейная регрессия**


На рисунке показана линия регрессии (красным цветом) для одномерных примеров (синие точки). Мы можем использовать эту строку, чтобы предсказать значение цели  для нового примера ввода без метки .
Чтобы получить эту оптимальную гиперплоскость (линию в 2-мерном случае), процедура оптимизации, которую мы используем, чтобы найти оптимальные значения для , пытается минимизировать следующее выражение:



Выражение   в вышеприведенной цели называется функцией потерь. Это мера штрафа за неправильную классификацию примера «». Этот конкретный выбор функции потерь называется квадратом потери ошибок.
Все алгоритмы обучения, основанные на моделях, имеют функцию потерь, и мы стараемся найти лучшую модель, чтобы минимизировать цель, известную как функция стоимости. При линейной регрессии функция стоимости определяется как средняя потеря. Средняя потеря для модели - это среднее значение всех штрафов, полученных путем применения модели к данным обучения.


####  Деревья решений<a name="4_1_2_2"></a>

*Деревья решений* – мы обсудили деревья решений и их использование для уменьшения размерности. Это очень популярный и простой метод. Их графика помогает увидеть, что происходит, а их движок требует систематического, документированного мыслительного процесса [4].

Идея этого алгоритма довольно проста. В каждом узле мы выбираем наилучшее разделение всех объектов и всех возможных точек разделения. Каждый сплит выбирается таким образом, чтобы максимизировать какой-то функционал. В деревьях классификации мы используем перекрестную энтропию и индекс Джини. В деревьях регрессии мы минимизируем сумму квадратов ошибок между прогнозирующей переменной целевых значений точек, которые попадают в этот регион, и той, которую мы присваиваем ей.

Мы выполняем эту процедуру рекурсивно для каждого узла и завершаем работу, когда выполняем критерии остановки. Они могут варьироваться от минимального количества листьев в узле до высоты дерева. Отдельные деревья используются очень редко, но по составу, как и многие другие, они создают очень эффективные алгоритмы, такие как Случайный лес или повышение градиентного дерева (Рисунок 14).


![](assets/ml_05.png)
**Деревья решений**


####  Метод опорных векторов<a name="4_1_2_3"></a>

*Метод опорных векторов* – он используется, когда в данных присутствует шум, и никакая гиперплоскость не может идеально отделить положительные примеры от отрицательных.
Для того, чтобы распространить на случаи, в которых данные не линейно разделимы, используется функция потерь шарнира:



Функция потери шарнира равна нулю, если лежит на правильной стороне границы решения. Для данных с неправильной стороны границы решения значение функции пропорционально расстоянию от границы решения. Затем мы пытаемся минимизировать следующую функцию стоимости:



где 	 – гиперпараметр, которая определяет компромисс между увеличением размера границы решения и обеспечением того, что каждый из них находится на правильной стороне границы решения. 
Значение C обычно выбирается экспериментально.

Действительно, если нам удастся преобразовать исходное пространство в пространство более высокой размерности, мы могли бы надеяться, что примеры станут линейно разделимыми в этом преобразованном пространстве. В SVM использование функции для неявного преобразования исходного пространства в пространство более высокого измерения во время оптимизации функции стоимости называется трюком ядра.


####  Алгоритм k-ближайших соседей<a name="4_1_2_4"></a>


KNN (k-ближайшие соседи) – алгоритм k-ближайших соседей использует весь набор данных в качестве обучающего набора, а не разделяет набор данных на обучающий набор и набор тестов.
Когда для нового экземпляра данных требуется результат, алгоритм KNN просматривает весь набор данных, чтобы найти k-ближайших экземпляров для нового экземпляра, или k экземпляров, наиболее похожих на новую запись, а затем выводит среднее значение результаты (для проблемы регрессии) или режим (наиболее частый класс) для задачи классификации. Значение k определяется пользователем.

Сходство между экземплярами рассчитывается с использованием таких мер, как евклидово расстояние и расстояние Хемминга.
Это самый четкий метод кластеризации, который все еще имеет некоторые недостатки. Прежде всего, мы должны знать количество кластеров. Во-вторых, результат зависит от точек, случайно выбранных в начале, и алгоритм не гарантирует, что мы достигнем глобального минимума функционала.


### Оценка и тестирование модели <a name="4_1_3"></a>

Цель этого этапа, разработать простейшую модель, способную быстро и достаточно хорошо сформулировать целевое значение. Эта цель достигнута с помощью модели тюнинга. Это оптимизация параметров модели для достижения максимальной производительности алгоритма.


####  Перекрестная проверка<a name="4_1_3_1"></a>

Одним из наиболее эффективных методов оценки и настройки модели является перекрестная проверка. *Перекрестная проверка* является наиболее часто используемым методом настройки. Это влечет за собой разделение учебного набора данных на десять равных частей (складок). Данная модель обучается только в девяти сгибах, а затем проверяется на десятой (ранее не учтенной). Тренировка продолжается до тех пор, пока каждая складка не будет оставлена ​​в стороне и использована для тестирования. В результате измерения производительности модели для каждого набора гиперпараметров рассчитывается перекрестная оценка. Модели обучаются с использованием различных наборов гиперпараметров, чтобы определить, какая модель имеет самую высокую точность прогнозирования. Перекрестно подтвержденный балл указывает на среднюю производительность модели по десяти сгибам удержания.
Затем мы тестируем модели с набором значений гиперпараметров, которые получили лучший перекрестно проверенный результат. Существуют различные метрики ошибок для задач машинного обучения.


####  Улучшение прогнозов с помощью методов ансамбля<a name="4_1_3_2"></a>

Улучшение прогнозов с помощью методов ансамбля – исследователи данных в основном создают и обучают одну или несколько десятков моделей, чтобы иметь возможность выбрать оптимальную модель среди хорошо работающих. Модели обычно показывают разные уровни точности, поскольку они допускают разные ошибки в новых точках данных. Есть способы улучшить аналитические результаты. Методы ансамбля моделей позволяют достичь более точного прогноза, используя несколько наиболее эффективных моделей и комбинируя их результаты. Точность, как правило, рассчитывается по средним ормедианским выходам всех моделей в ансамбле. Среднее значение - это общее количество голосов, поделенное на их количество. Медиана представляет собой средний балл для голосов, упорядоченных по размеру.

Распространенными методами ансамбля являются Stacking, Bagging и Boosting.

*Stacking* –  Этот подход, также известный как многоуровневое обобщение, предлагает разработку метамодели или ученика более высокого уровня путем объединения нескольких базовых моделей. Stacking обычно используются для объединения моделей различных типов. Цель этого метода – уменьшить ошибку обобщения.

*Bagging* –  (начальная загрузка). Это метод последовательного объединения моделей. Сначала обучающий набор данных разбивается на подмножества. Затем модели обучаются на каждом из этих подмножеств. После этого прогнозы объединяются с использованием среднего или большинства голосов. Bagging помогает уменьшить ошибку дисперсии и избежать модели переобучения.

*Boosting* –  Согласно этой методике, работа делится на два этапа. Сначала мы используем подмножества исходного набора данных, чтобы разработать несколько моделей со средней эффективностью, а затем объединяем их, чтобы повысить производительность, используя большинство голосов. Каждая модель обучается на подмножестве, полученном в результате исполнения предыдущей модели, и концентрируется на неправильно классифицированных записях.

Можно развернуть модель, которая наиболее точно прогнозирует значения результатов в тестовых данных.


###  Развертывание модели<a name="4_1_4"></a>


Развертывание модели (Model deployment) – этап развертывания модели включает в себя ввод модели в эксплуатацию.
После того, как мы выбрали надежную модель и определили ее требования к производительности, мы интегрируем модель с производственной средой.

Затем мы измеряем производительность модели с помощью A / B-тестирования. Тестирование может показать, как, например, число клиентов, работающих с моделью, используемой для персональной рекомендации, соотносится с бизнес-целью.

Рабочий процесс развертывания зависит от бизнес-инфраструктуры и проблемы, которую мы хотим решить. Прогностическая модель может быть ядром новой отдельной программы или может быть включена в существующее программное обеспечение.

Производительность модели также зависит от того, выполнили ли мы вышеупомянутые этапы (подготовка и предварительная обработка набора данных, моделирование) вручную с использованием собственной ИТ-инфраструктуры или автоматически с одним из машинного обучения в качестве сервисных продуктов.


*Пакетный прогноз* – Это вариант развертывания подходит, когда нам не нужны прогнозы на постоянной основе. Когда мы выбираем этот тип развертывания, мы получаем один прогноз для группы наблюдений. Модель обучается на статическом наборе данных и выводит прогноз. Развертывание не требуется, если необходим единый прогноз. Например, мы можем решить проблему классификации, чтобы узнать, принимает ли определенная группа клиентов предложение или нет.

*Веб-сервис* – такой рабочий процесс машинного обучения позволяет получать прогнозы практически в реальном времени. Модель, однако, обрабатывает одну запись из набора данных за раз и делает для нее прогнозы.

*Прогноз в реальном времени* (потоковое в реальном времени) – с помощью потоковой аналитики в реальном времени мы можем мгновенно анализировать потоковые данные в реальном времени и быстро реагировать на события, которые происходят в любой момент. Прогнозирование в реальном времени позволяет обрабатывать данные датчиков или рынка, данные из Интернета вещей или мобильных устройств, а также из мобильных или настольных приложений и веб-сайтов.







