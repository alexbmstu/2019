- [Введение](#1)
	- [Алгоритмы предварительной обработки данных](#1_1)
	- [Алгоритмы машинного обучения](#1_2)
		- [Обучение с учителем](#1_2_1)
		- [Обучение без учителя](#1_2_2)
	- [Типовая вычислительная инфраструктура для машинного обучения ](#1_3)
	- [Проект хакатона](#1_4)
	- [Оборудование и настройка компьютера разработчика](#1_5)
- [День 1. Управление виртуальным ЦОД](#2)
	- [Доступ к виртальному ЦОД](#21)
	- [Создание виртуальной машины сетевого шлюза и установка ОС](#22)
	- [Создание виртуальной машины в локальной сети и настройка шлюза](#24)
	- [Уcтановка фреймворка Anaconda и Jupyter Notebooks](#25)
- [День 2. Практикум в Jupyter Notebook](#3)
	- [Работа с данными](#3)
- [День 3. Алгоритмы машинного обучения](#4)
	- [Методология машинного обучения](#4_1)
	- [Предварительная обработка данных](#4_2)
		- [Очистка данных](#4_2_1)
		- [Масштабирования](#4_2_2)
		- [Уменьшение размерности](#4_2_3)
		- [Алгоритм выбора признаков](#4_2_4)
		- [Обратное удаление признаков](#4_2_5)
		- [Выбор вперед](#4_2_6)
		- [Анализ главных компонентов](#4_2_7)
		- [Независимый компонентный анализ](#4_2_8)
		- [Факторный анализ](#4_2_9)
		- [Многообразное обучение или нелинейное уменьшение размерности](#4_2_10)
		- [Локально линейное вложение](#4_2_11)
		- [Унифицированная аппроксимация и проекция многообразия](#4_2_12)
		- [Соотношение пропущенных значений](#4_2_13)
		- [Фильтр низкой дисперсии](#4_2_14)
		- [Фильтр высокой корреляции](#4_2_15)
		- [Случайный лес](#4_2_16)
		- [Факторный анализ](#4_2_17)
		- [Анализ основных компонентов](#4_2_18)
		- [Разделение набора данных](#4_2_19)
	- [Алгоритмы машинного обучения](#4_3)
		- [ Линейная регрессия](#4_3_1)
		- [ Деревья решений](#4_3_2)
		- [ Метод опорных векторов](#4_3_3)
		- [ Алгоритм k-ближайших соседей](#4_3_4)
	- [Оценка и тестирование модели](#4_4)
		- [ Перекрестная проверка](#4_4_1)
		- [ Улучшение прогнозов с помощью методов ансамбля](#4_4_2)
	- [ Развертывание модели](#4_5)
- [Дополнительные источники](#a001)
